"""
FaceNetäººè„¸è¯†åˆ«å™¨å°è£…
ä½¿ç”¨FaceNetæå–ç‰¹å¾å¹¶ä½¿ç”¨SVMè¿›è¡Œè¯†åˆ«
"""
import numpy as np
import cv2
import pickle
from typing import Optional, Tuple, List
from pathlib import Path
import torch
from facenet_pytorch import InceptionResnetV1
from PIL import Image

from config.settings import Config


class FaceNetRecognizer:
    """FaceNetäººè„¸è¯†åˆ«å™¨"""
    
    def __init__(self, embeddings_path: Optional[str] = None, 
                 svm_path: Optional[str] = None):
        """
        åˆå§‹åŒ–FaceNetè¯†åˆ«å™¨
        
        Args:
            embeddings_path: äººè„¸ç‰¹å¾æ–‡ä»¶è·¯å¾„
            svm_path: SVMåˆ†ç±»å™¨è·¯å¾„
        """
        self.embeddings_path = embeddings_path or Config.FACENET_EMBEDDINGS
        self.svm_path = svm_path or Config.FACENET_SVM
        self.device = Config.get_device()
        
        # æ¨¡å‹å’Œæ•°æ®
        self.facenet_model = None
        self.svm_model = None
        self.embeddings = None
        self.labels = None
        self.label_to_id = {}
        self.id_to_label = {}
        
        # åŠ è½½æ¨¡å‹
        self.load_models()
    
    def load_models(self):
        """åŠ è½½FaceNetå’ŒSVMæ¨¡å‹"""
        try:
            # åŠ è½½FaceNetæ¨¡å‹
            print("åŠ è½½FaceNetæ¨¡å‹...")
            self.facenet_model = InceptionResnetV1(pretrained='vggface2').eval()
            self.facenet_model.to(self.device)
            print(f"âœ“ FaceNetæ¨¡å‹åŠ è½½æˆåŠŸ (è®¾å¤‡: {self.device})")
            
            # åŠ è½½å·²ä¿å­˜çš„ç‰¹å¾å’ŒSVM
            if Path(self.embeddings_path).exists() and Path(self.svm_path).exists():
                self.load_trained_data()
            else:
                print("âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®,éœ€è¦å…ˆè®­ç»ƒæ¨¡å‹")
        
        except Exception as e:
            print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def load_trained_data(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ•°æ®"""
        try:
            # åŠ è½½ç‰¹å¾
            data = np.load(self.embeddings_path)
            self.embeddings = data['embeddings']
            self.labels = data['labels']
            
            # åˆ›å»ºæ ‡ç­¾æ˜ å°„
            unique_labels = np.unique(self.labels)
            self.label_to_id = {label: idx for idx, label in enumerate(unique_labels)}
            self.id_to_label = {idx: label for label, idx in self.label_to_id.items()}
            
            # åŠ è½½SVM
            with open(self.svm_path, 'rb') as f:
                self.svm_model = pickle.load(f)
            
            print(f"âœ“ åŠ è½½è®­ç»ƒæ•°æ®æˆåŠŸ (ç”¨æˆ·æ•°: {len(unique_labels)})")
        
        except Exception as e:
            print(f"âœ— åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            raise
    
    def extract_embedding(self, face_image: np.ndarray) -> np.ndarray:
        """
        æå–äººè„¸ç‰¹å¾
        
        Args:
            face_image: äººè„¸å›¾åƒ (BGRæ ¼å¼)
            
        Returns:
            512ç»´ç‰¹å¾å‘é‡
        """
        if self.facenet_model is None:
            raise RuntimeError("FaceNetæ¨¡å‹æœªåŠ è½½")
        
        # é¢„å¤„ç†
        face_rgb = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)
        face_pil = Image.fromarray(face_rgb)
        face_resized = face_pil.resize(Config.FACE_SIZE)
        
        # è½¬æ¢ä¸ºtensor
        face_tensor = torch.from_numpy(np.array(face_resized)).float()
        face_tensor = face_tensor.permute(2, 0, 1)  # HWC -> CHW
        face_tensor = (face_tensor - 127.5) / 128.0  # å½’ä¸€åŒ–åˆ°[-1, 1]
        face_tensor = face_tensor.unsqueeze(0).to(self.device)
        
        # æå–ç‰¹å¾
        with torch.no_grad():
            embedding = self.facenet_model(face_tensor)
        
        return embedding.cpu().numpy().flatten()
    
    def recognize(self, face_image: np.ndarray) -> Tuple[Optional[int], float]:
        """
        è¯†åˆ«äººè„¸
        
        Args:
            face_image: äººè„¸å›¾åƒ
            
        Returns:
            (user_id, confidence) or (None, 0.0)
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒæ•°æ®
        if self.embeddings is None or self.labels is None:
            return None, 0.0
        
        try:
            # æå–ç‰¹å¾
            embedding = self.extract_embedding(face_image)
            
            # ç‰¹æ®Šæƒ…å†µï¼šåªæœ‰1ä¸ªç”¨æˆ·æ—¶ï¼Œä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
            unique_labels = np.unique(self.labels)
            if len(unique_labels) == 1:
                # è®¡ç®—ä¸æ‰€æœ‰å·²çŸ¥ç‰¹å¾çš„ä½™å¼¦ç›¸ä¼¼åº¦
                similarities = []
                for known_embedding in self.embeddings:
                    similarity = np.dot(embedding, known_embedding) / (
                        np.linalg.norm(embedding) * np.linalg.norm(known_embedding)
                    )
                    similarities.append(similarity)
                
                # å–æœ€å¤§ç›¸ä¼¼åº¦ï¼ˆèŒƒå›´ [-1, 1]ï¼‰
                max_similarity = float(np.max(similarities))
                
                # ä½™å¼¦ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä¸¥æ ¼ï¼‰
                # å¯¹äºå•ç”¨æˆ·ï¼Œè¦æ±‚è‡³å°‘ 0.75 çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆè¡¨ç¤ºå‘é‡å¤¹è§’ < 41åº¦ï¼‰
                # è¿™æ ·å¯ä»¥æœ‰æ•ˆé˜²æ­¢æœªæ³¨å†Œç”¨æˆ·è¢«è¯¯è¯†åˆ«
                cosine_threshold = 0.75
                
                if max_similarity < cosine_threshold:
                    # æœªè¾¾åˆ°é˜ˆå€¼ï¼Œè¿”å›None
                    # è½¬æ¢ä¸º [0, 1] èŒƒå›´ç”¨äºæ˜¾ç¤º
                    confidence = (max_similarity + 1) / 2
                    return None, confidence
                
                # é€šè¿‡é˜ˆå€¼ï¼Œè¿”å›ç”¨æˆ·IDå’Œç½®ä¿¡åº¦
                confidence = (max_similarity + 1) / 2
                return int(unique_labels[0]), confidence
            
            # å¤šç”¨æˆ·æƒ…å†µï¼šä½¿ç”¨SVM
            if self.svm_model is None:
                return None, 0.0
            
            # SVMé¢„æµ‹
            prediction = self.svm_model.predict([embedding])[0]
            
            # è·å–å†³ç­–å‡½æ•°å€¼(ç½®ä¿¡åº¦)
            decision_values = self.svm_model.decision_function([embedding])
            
            # è®¡ç®—ç½®ä¿¡åº¦
            if len(decision_values.shape) > 1:
                # å¤šåˆ†ç±»
                confidence = float(np.max(decision_values))
            else:
                # äºŒåˆ†ç±»
                confidence = float(abs(decision_values[0]))
            
            # å½’ä¸€åŒ–ç½®ä¿¡åº¦åˆ°[0, 1]
            confidence = 1 / (1 + np.exp(-confidence))
            
            # æ£€æŸ¥é˜ˆå€¼
            if confidence < Config.FACE_RECOGNITION_THRESHOLD:
                return None, confidence
            
            # è·å–ç”¨æˆ·ID
            user_id = int(prediction)
            
            return user_id, confidence
        
        except Exception as e:
            print(f"è¯†åˆ«å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None, 0.0
    
    def recognize_batch(self, face_images: List[np.ndarray]) -> List[Tuple[Optional[int], float]]:
        """
        æ‰¹é‡è¯†åˆ«äººè„¸
        
        Args:
            face_images: äººè„¸å›¾åƒåˆ—è¡¨
            
        Returns:
            [(user_id, confidence), ...]
        """
        results = []
        for face_image in face_images:
            result = self.recognize(face_image)
            results.append(result)
        return results
    
    def add_user(self, user_id: int, face_images: List[np.ndarray]):
        """
        æ·»åŠ æ–°ç”¨æˆ·
        
        Args:
            user_id: ç”¨æˆ·ID
            face_images: ç”¨æˆ·çš„äººè„¸å›¾åƒåˆ—è¡¨
        """
        # æå–æ‰€æœ‰äººè„¸çš„ç‰¹å¾
        new_embeddings = []
        for face_image in face_images:
            embedding = self.extract_embedding(face_image)
            new_embeddings.append(embedding)
        
        new_embeddings = np.array(new_embeddings)
        new_labels = np.array([user_id] * len(new_embeddings))
        
        # åˆå¹¶åˆ°ç°æœ‰æ•°æ®
        if self.embeddings is not None:
            self.embeddings = np.vstack([self.embeddings, new_embeddings])
            self.labels = np.hstack([self.labels, new_labels])
        else:
            self.embeddings = new_embeddings
            self.labels = new_labels
        
        # é‡æ–°è®­ç»ƒSVM
        self.train_svm()
        
        # ä¿å­˜
        self.save_trained_data()
    
    def train_svm(self):
        """è®­ç»ƒSVMåˆ†ç±»å™¨"""
        from sklearn.svm import SVC
        
        # æ£€æŸ¥ç±»åˆ«æ•°é‡
        unique_labels = np.unique(self.labels)
        n_classes = len(unique_labels)
        
        if n_classes < 2:
            print(f"âš ï¸  åªæœ‰ {n_classes} ä¸ªç”¨æˆ·ï¼Œè·³è¿‡SVMè®­ç»ƒï¼ˆéœ€è¦è‡³å°‘2ä¸ªç”¨æˆ·ï¼‰")
            self.svm_model = None
            return
        
        print(f"è®­ç»ƒSVMåˆ†ç±»å™¨... ({n_classes} ä¸ªç”¨æˆ·)")
        self.svm_model = SVC(kernel='linear', probability=True)
        self.svm_model.fit(self.embeddings, self.labels)
        print("âœ“ SVMè®­ç»ƒå®Œæˆ")
    
    def save_trained_data(self):
        """ä¿å­˜è®­ç»ƒæ•°æ®"""
        # ä¿å­˜ç‰¹å¾
        np.savez(
            self.embeddings_path,
            embeddings=self.embeddings,
            labels=self.labels
        )
        
        # ä¿å­˜SVM
        with open(self.svm_path, 'wb') as f:
            pickle.dump(self.svm_model, f)
        
        print(f"âœ“ è®­ç»ƒæ•°æ®å·²ä¿å­˜")
    
    def remove_user(self, user_id: int):
        """
        åˆ é™¤ç”¨æˆ·
        
        Args:
            user_id: ç”¨æˆ·ID
        """
        print(f"\n{'='*60}")
        print(f"ğŸ—‘ï¸  [FaceNetRecognizer] å¼€å§‹åˆ é™¤ç”¨æˆ· {user_id}")
        print(f"{'='*60}")
        
        if self.embeddings is None or self.labels is None:
            print("âš ï¸  æ²¡æœ‰è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡åˆ é™¤")
            return
        
        # æ˜¾ç¤ºåˆ é™¤å‰çš„çŠ¶æ€
        unique_labels_before = np.unique(self.labels)
        print(f"\nğŸ“Š åˆ é™¤å‰çŠ¶æ€:")
        print(f"  - æ€»æ ·æœ¬æ•°: {len(self.embeddings)}")
        print(f"  - ç”¨æˆ·æ•°: {len(unique_labels_before)}")
        print(f"  - ç”¨æˆ·IDåˆ—è¡¨: {unique_labels_before}")
        
        # ç»Ÿè®¡è¦åˆ é™¤çš„ç”¨æˆ·çš„æ ·æœ¬æ•°
        # æ³¨æ„ï¼šlabelså¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•´æ•°ï¼Œéœ€è¦ç»Ÿä¸€æ¯”è¾ƒ
        user_id_str = str(user_id)
        user_samples_int = np.sum(self.labels == user_id)
        user_samples_str = np.sum(self.labels == user_id_str)
        user_samples = user_samples_int + user_samples_str
        
        print(f"\nğŸ¯ ç›®æ ‡ç”¨æˆ· {user_id}:")
        print(f"  - æ ·æœ¬æ•°ï¼ˆæ•´æ•°åŒ¹é…ï¼‰: {user_samples_int}")
        print(f"  - æ ·æœ¬æ•°ï¼ˆå­—ç¬¦ä¸²åŒ¹é…ï¼‰: {user_samples_str}")
        print(f"  - æ€»æ ·æœ¬æ•°: {user_samples}")
        
        if user_samples == 0:
            print(f"âš ï¸  ç”¨æˆ· {user_id} æ²¡æœ‰æ ·æœ¬ï¼Œæ— éœ€åˆ é™¤")
            return
        
        # è¿‡æ»¤æ‰è¯¥ç”¨æˆ·çš„æ•°æ®ï¼ˆåŒæ—¶åŒ¹é…æ•´æ•°å’Œå­—ç¬¦ä¸²ï¼‰
        print(f"\nğŸ”„ å¼€å§‹è¿‡æ»¤æ•°æ®...")
        mask = (self.labels != user_id) & (self.labels != user_id_str)
        self.embeddings = self.embeddings[mask]
        self.labels = self.labels[mask]
        
        # æ˜¾ç¤ºåˆ é™¤åçš„çŠ¶æ€
        unique_labels_after = np.unique(self.labels) if len(self.labels) > 0 else np.array([])
        print(f"\nğŸ“Š åˆ é™¤åçŠ¶æ€:")
        print(f"  - æ€»æ ·æœ¬æ•°: {len(self.embeddings)}")
        print(f"  - ç”¨æˆ·æ•°: {len(unique_labels_after)}")
        print(f"  - ç”¨æˆ·IDåˆ—è¡¨: {unique_labels_after}")
        print(f"  - å·²åˆ é™¤æ ·æœ¬æ•°: {user_samples}")
        
        # é‡æ–°è®­ç»ƒ
        if len(self.embeddings) > 0:
            print(f"\nğŸ”„ é‡æ–°è®­ç»ƒæ¨¡å‹...")
            self.train_svm()
            print(f"ğŸ’¾ ä¿å­˜æ›´æ–°åçš„æ¨¡å‹æ–‡ä»¶...")
            self.save_trained_data()
            print(f"âœ… æ¨¡å‹å·²æ›´æ–°å¹¶ä¿å­˜")
        else:
            print("âš ï¸  æ‰€æœ‰ç”¨æˆ·å·²åˆ é™¤ï¼Œæ¸…ç©ºæ¨¡å‹")
            self.svm_model = None
        
        print(f"\n{'='*60}")
        print(f"âœ… ç”¨æˆ· {user_id} åˆ é™¤å®Œæˆ")
        print(f"{'='*60}\n")
    
    def get_user_count(self) -> int:
        """è·å–æ³¨å†Œç”¨æˆ·æ•°é‡"""
        if self.labels is None:
            return 0
        return len(np.unique(self.labels))
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if self.facenet_model is not None:
            del self.facenet_model
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    recognizer = FaceNetRecognizer()
    
    print(f"æ³¨å†Œç”¨æˆ·æ•°: {recognizer.get_user_count()}")
    
    # æµ‹è¯•è¯†åˆ«
    cap = cv2.VideoCapture(0)
    from yolo_face_detector import YOLOFaceDetector
    detector = YOLOFaceDetector()
    
    print("æŒ‰ 'q' é€€å‡º")
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æ£€æµ‹äººè„¸
        faces = detector.detect_faces(frame, return_confidence=True)
        
        for face in faces:
            x1, y1, x2, y2 = face[:4]
            
            # è£å‰ªäººè„¸
            face_img = detector.crop_face(frame, face)
            if face_img is not None:
                # è¯†åˆ«
                user_id, confidence = recognizer.recognize(face_img)
                
                # ç»˜åˆ¶
                color = (0, 255, 0) if user_id is not None else (0, 0, 255)
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                
                text = f"User {user_id} ({confidence:.2f})" if user_id else "Unknown"
                cv2.putText(frame, text, (x1, y1 - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        cv2.imshow('Face Recognition', frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
