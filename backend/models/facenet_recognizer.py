"""
FaceNetäººè„¸è¯†åˆ«å™¨å°è£…
ä½¿ç”¨FaceNetæå–ç‰¹å¾å¹¶ä½¿ç”¨SVMè¿›è¡Œè¯†åˆ«
æ”¯æŒæ•°æ®å¢å¼ºå’Œè´¨é‡æ£€æµ‹ä»¥æé«˜è¯†åˆ«å‡†ç¡®ç‡
"""
import numpy as np
import cv2
import pickle
from typing import Optional, Tuple, List
from pathlib import Path
import torch
from facenet_pytorch import InceptionResnetV1
from PIL import Image

from config.settings import Config


class FaceNetRecognizer:
    """FaceNetäººè„¸è¯†åˆ«å™¨"""
    
    def __init__(self, embeddings_path: Optional[str] = None, 
                 svm_path: Optional[str] = None):
        """
        åˆå§‹åŒ–FaceNetè¯†åˆ«å™¨
        
        Args:
            embeddings_path: äººè„¸ç‰¹å¾æ–‡ä»¶è·¯å¾„
            svm_path: SVMåˆ†ç±»å™¨è·¯å¾„
        """
        self.embeddings_path = embeddings_path or Config.FACENET_EMBEDDINGS
        self.svm_path = svm_path or Config.FACENET_SVM
        self.device = Config.get_device()
        
        # æ¨¡å‹å’Œæ•°æ®
        self.facenet_model = None
        self.svm_model = None
        self.embeddings = None
        self.labels = None
        self.label_to_id = {}
        self.id_to_label = {}
        
        # åŠ è½½æ¨¡å‹
        self.load_models()
    
    def load_models(self):
        """åŠ è½½FaceNetå’ŒSVMæ¨¡å‹"""
        try:
            # åŠ è½½FaceNetæ¨¡å‹
            print("åŠ è½½FaceNetæ¨¡å‹...")
            self.facenet_model = InceptionResnetV1(pretrained='vggface2').eval()
            self.facenet_model.to(self.device)
            print(f"âœ“ FaceNetæ¨¡å‹åŠ è½½æˆåŠŸ (è®¾å¤‡: {self.device})")
            
            # åŠ è½½å·²ä¿å­˜çš„ç‰¹å¾å’ŒSVM
            if Path(self.embeddings_path).exists() and Path(self.svm_path).exists():
                self.load_trained_data()
            else:
                print("âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®,éœ€è¦å…ˆè®­ç»ƒæ¨¡å‹")
        
        except Exception as e:
            print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def load_trained_data(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ•°æ®"""
        try:
            # åŠ è½½ç‰¹å¾ï¼ˆå…è®¸pickleä»¥æ”¯æŒobjectç±»å‹çš„labelsï¼‰
            data = np.load(self.embeddings_path, allow_pickle=True)
            self.embeddings = data['embeddings']
            self.labels = data['labels']
            
            # åˆ›å»ºæ ‡ç­¾æ˜ å°„
            unique_labels = np.unique(self.labels)
            self.label_to_id = {label: idx for idx, label in enumerate(unique_labels)}
            self.id_to_label = {idx: label for label, idx in self.label_to_id.items()}
            
            # åŠ è½½SVM
            with open(self.svm_path, 'rb') as f:
                self.svm_model = pickle.load(f)
            
            print(f"âœ“ åŠ è½½è®­ç»ƒæ•°æ®æˆåŠŸ (ç”¨æˆ·æ•°: {len(unique_labels)})")
        
        except Exception as e:
            print(f"âœ— åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            raise
    
    def extract_embedding(self, face_image: np.ndarray) -> np.ndarray:
        """
        æå–äººè„¸ç‰¹å¾
        
        Args:
            face_image: äººè„¸å›¾åƒ (BGRæ ¼å¼)
            
        Returns:
            512ç»´ç‰¹å¾å‘é‡
        """
        if self.facenet_model is None:
            raise RuntimeError("FaceNetæ¨¡å‹æœªåŠ è½½")
        
        # é¢„å¤„ç†
        face_rgb = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)
        face_pil = Image.fromarray(face_rgb)
        face_resized = face_pil.resize(Config.FACE_SIZE)
        
        # è½¬æ¢ä¸ºtensor
        face_tensor = torch.from_numpy(np.array(face_resized)).float()
        face_tensor = face_tensor.permute(2, 0, 1)  # HWC -> CHW
        face_tensor = (face_tensor - 127.5) / 128.0  # å½’ä¸€åŒ–åˆ°[-1, 1]
        face_tensor = face_tensor.unsqueeze(0).to(self.device)
        
        # æå–ç‰¹å¾
        with torch.no_grad():
            embedding = self.facenet_model(face_tensor)
        
        return embedding.cpu().numpy().flatten()
    
    def recognize(self, face_image: np.ndarray) -> Tuple[Optional[int], float]:
        """
        è¯†åˆ«äººè„¸
        
        Args:
            face_image: äººè„¸å›¾åƒ
            
        Returns:
            (user_id, confidence) or (None, 0.0)
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒæ•°æ®
        if self.embeddings is None or self.labels is None:
            return None, 0.0
        
        try:
            # ğŸ¯ æ­¥éª¤1ï¼šæå–ç‰¹å¾
            embedding = self.extract_embedding(face_image)
            
            # ğŸ¯ æ­¥éª¤2ï¼šç‰¹å¾å½’ä¸€åŒ–ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
            embedding = embedding / np.linalg.norm(embedding)
            
            # ç‰¹æ®Šæƒ…å†µï¼šåªæœ‰1ä¸ªç”¨æˆ·æ—¶ï¼Œä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
            unique_labels = np.unique(self.labels)
            
            print(f"\n{'='*60}")
            print(f"ğŸ” [FaceNetRecognizer] å¼€å§‹è¯†åˆ«")
            print(f"{'='*60}")
            print(f"ğŸ“Š æ¨¡å‹çŠ¶æ€:")
            print(f"  - æ³¨å†Œç”¨æˆ·æ•°: {len(unique_labels)}")
            print(f"  - ç”¨æˆ·IDåˆ—è¡¨: {unique_labels}")
            print(f"  - æ€»æ ·æœ¬æ•°: {len(self.embeddings)}")
            
            if len(unique_labels) == 1:
                # è®¡ç®—ä¸æ‰€æœ‰å·²çŸ¥ç‰¹å¾çš„ä½™å¼¦ç›¸ä¼¼åº¦
                similarities = []
                for known_embedding in self.embeddings:
                    similarity = np.dot(embedding, known_embedding) / (
                        np.linalg.norm(embedding) * np.linalg.norm(known_embedding)
                    )
                    similarities.append(similarity)
                
                # å–æœ€å¤§ç›¸ä¼¼åº¦ï¼ˆèŒƒå›´ [-1, 1]ï¼‰
                max_similarity = float(np.max(similarities))
                min_similarity = float(np.min(similarities))
                avg_similarity = float(np.mean(similarities))
                
                print(f"\nğŸ¯ å•ç”¨æˆ·æ¨¡å¼ - ä½™å¼¦ç›¸ä¼¼åº¦:")
                print(f"  - æœ€å¤§ç›¸ä¼¼åº¦: {max_similarity:.6f}")
                print(f"  - æœ€å°ç›¸ä¼¼åº¦: {min_similarity:.6f}")
                print(f"  - å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.6f}")
                print(f"  - æ ·æœ¬æ•°: {len(similarities)}")
                
                # ä½™å¼¦ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä¸¥æ ¼ï¼‰
                # å¯¹äºå•ç”¨æˆ·ï¼Œè¦æ±‚è‡³å°‘ 0.75 çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆè¡¨ç¤ºå‘é‡å¤¹è§’ < 41åº¦ï¼‰
                # è¿™æ ·å¯ä»¥æœ‰æ•ˆé˜²æ­¢æœªæ³¨å†Œç”¨æˆ·è¢«è¯¯è¯†åˆ«
                cosine_threshold = 0.75
                print(f"  - é˜ˆå€¼: {cosine_threshold}")
                
                if max_similarity < cosine_threshold:
                    # æœªè¾¾åˆ°é˜ˆå€¼ï¼Œè¿”å›None
                    # è½¬æ¢ä¸º [0, 1] èŒƒå›´ç”¨äºæ˜¾ç¤º
                    confidence = (max_similarity + 1) / 2
                    print(f"\nâŒ æœªé€šè¿‡é˜ˆå€¼æ£€æŸ¥:")
                    print(f"  - æœ€å¤§ç›¸ä¼¼åº¦ {max_similarity:.6f} < é˜ˆå€¼ {cosine_threshold}")
                    print(f"  - è½¬æ¢åç½®ä¿¡åº¦: {confidence:.6f}")
                    print(f"{'='*60}\n")
                    return None, confidence
                
                # é€šè¿‡é˜ˆå€¼ï¼Œè¿”å›ç”¨æˆ·IDå’Œç½®ä¿¡åº¦
                confidence = (max_similarity + 1) / 2
                print(f"\nâœ… é€šè¿‡é˜ˆå€¼æ£€æŸ¥:")
                print(f"  - æœ€å¤§ç›¸ä¼¼åº¦ {max_similarity:.6f} >= é˜ˆå€¼ {cosine_threshold}")
                print(f"  - è½¬æ¢åç½®ä¿¡åº¦: {confidence:.6f}")
                
                # ğŸ”§ ä¿®å¤ï¼šå°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›å­—ç¬¦ä¸²
                try:
                    user_id = int(unique_labels[0])
                    print(f"  - è¯†åˆ«ç”¨æˆ·ID: {user_id}")
                    print(f"{'='*60}\n")
                except (ValueError, TypeError):
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ç±»å‹çš„ç”¨æˆ·åï¼Œè¿”å›Noneï¼ˆä¸æ˜¯æ•°å­—IDï¼‰
                    print(f"âš ï¸  å•ç”¨æˆ·æ¨¡å¼ä¸‹çš„labelä¸æ˜¯æ•°å­—ID: {unique_labels[0]}")
                    print(f"{'='*60}\n")
                    return None, confidence
                return user_id, confidence
            
            # å¤šç”¨æˆ·æƒ…å†µï¼šä½¿ç”¨SVM
            print(f"\nğŸ¯ å¤šç”¨æˆ·æ¨¡å¼ - SVMåˆ†ç±»:")
            
            if self.svm_model is None:
                print(f"âŒ SVMæ¨¡å‹æœªè®­ç»ƒ")
                print(f"{'='*60}\n")
                return None, 0.0
            
            # ğŸ¯ æ­¥éª¤1ï¼šSVMé¢„æµ‹
            prediction = self.svm_model.predict([embedding])[0]
            print(f"  - SVMé¢„æµ‹: {prediction}")
            
            # ğŸ¯ æ­¥éª¤2ï¼šè·å–æ¦‚ç‡åˆ†å¸ƒï¼ˆæ¯”å†³ç­–å‡½æ•°æ›´å¯é ï¼‰
            probabilities = self.svm_model.predict_proba([embedding])[0]
            classes = self.svm_model.classes_
            
            # æ‰¾åˆ°é¢„æµ‹ç±»åˆ«çš„ç´¢å¼•
            pred_idx = np.where(classes == prediction)[0][0]
            confidence = float(probabilities[pred_idx])
            
            print(f"\nğŸ“Š æ¦‚ç‡åˆ†å¸ƒåˆ†æ:")
            print(f"  - é¢„æµ‹ç±»åˆ«: {prediction}")
            print(f"  - é¢„æµ‹æ¦‚ç‡: {confidence:.6f}")
            
            # æ˜¾ç¤ºå‰3ä¸ªæœ€é«˜æ¦‚ç‡
            top3_indices = np.argsort(probabilities)[-3:][::-1]
            print(f"\n  Top 3 å€™é€‰:")
            for i, idx in enumerate(top3_indices, 1):
                print(f"    {i}. ç”¨æˆ· {classes[idx]}: {probabilities[idx]:.6f}")
            
            # ğŸ¯ æ­¥éª¤3ï¼šäºŒæ¬¡éªŒè¯ - æ£€æŸ¥ä¸æ¬¡é«˜åˆ†çš„å·®è·
            sorted_probs = np.sort(probabilities)[::-1]
            if len(sorted_probs) >= 2:
                max_prob = sorted_probs[0]
                second_max_prob = sorted_probs[1]
                prob_gap = max_prob - second_max_prob
                
                print(f"\nğŸ” äºŒæ¬¡éªŒè¯:")
                print(f"  - æœ€é«˜æ¦‚ç‡: {max_prob:.6f}")
                print(f"  - æ¬¡é«˜æ¦‚ç‡: {second_max_prob:.6f}")
                print(f"  - æ¦‚ç‡å·®è·: {prob_gap:.6f}")
                
                # å¦‚æœå·®è·å¤ªå°ï¼Œè¯´æ˜æ¨¡å‹ä¸ç¡®å®š
                min_gap = 0.15  # è‡³å°‘15%çš„å·®è·
                if prob_gap < min_gap:
                    print(f"  âš ï¸  æ¦‚ç‡å·®è·è¿‡å° ({prob_gap:.6f} < {min_gap})")
                    print(f"  âš ï¸  æ¨¡å‹æ— æ³•æ˜ç¡®åŒºåˆ†ï¼Œæ‹’ç»è¯†åˆ«")
                    print(f"\nâŒ æœªé€šè¿‡äºŒæ¬¡éªŒè¯")
                    print(f"{'='*60}\n")
                    return None, confidence
                else:
                    print(f"  âœ“ æ¦‚ç‡å·®è·å……è¶³ ({prob_gap:.6f} >= {min_gap})")
            
            # ğŸ¯ æ­¥éª¤4ï¼šé˜ˆå€¼æ£€æŸ¥
            print(f"\nğŸ¯ é˜ˆå€¼æ£€æŸ¥:")
            print(f"  - ç½®ä¿¡åº¦: {confidence:.6f}")
            print(f"  - é˜ˆå€¼: {Config.FACE_RECOGNITION_THRESHOLD}")
            
            if confidence < Config.FACE_RECOGNITION_THRESHOLD:
                print(f"\nâŒ æœªé€šè¿‡é˜ˆå€¼æ£€æŸ¥:")
                print(f"  - ç½®ä¿¡åº¦ {confidence:.6f} < é˜ˆå€¼ {Config.FACE_RECOGNITION_THRESHOLD}")
                print(f"{'='*60}\n")
                return None, confidence
            
            print(f"\nâœ… é€šè¿‡æ‰€æœ‰æ£€æŸ¥:")
            print(f"  - ç½®ä¿¡åº¦: {confidence:.6f} >= é˜ˆå€¼ {Config.FACE_RECOGNITION_THRESHOLD}")
            
            # ğŸ”§ ä¿®å¤ï¼šè·å–ç”¨æˆ·IDï¼Œå°è¯•è½¬æ¢ä¸ºæ•´æ•°
            try:
                user_id = int(prediction)
                print(f"  - è¯†åˆ«ç”¨æˆ·ID: {user_id}")
                print(f"{'='*60}\n")
            except (ValueError, TypeError):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ç±»å‹çš„ç”¨æˆ·åï¼Œè¿”å›Noneï¼ˆä¸æ˜¯æ•°å­—IDï¼‰
                print(f"âš ï¸  SVMé¢„æµ‹çš„labelä¸æ˜¯æ•°å­—ID: {prediction}")
                print(f"{'='*60}\n")
                return None, confidence
            
            return user_id, confidence
        
        except Exception as e:
            print(f"è¯†åˆ«å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None, 0.0
    
    def recognize_batch(self, face_images: List[np.ndarray]) -> List[Tuple[Optional[int], float]]:
        """
        æ‰¹é‡è¯†åˆ«äººè„¸
        
        Args:
            face_images: äººè„¸å›¾åƒåˆ—è¡¨
            
        Returns:
            [(user_id, confidence), ...]
        """
        results = []
        for face_image in face_images:
            result = self.recognize(face_image)
            results.append(result)
        return results
    
    def check_face_quality(self, face_image: np.ndarray) -> Tuple[bool, str]:
        """
        æ£€æŸ¥äººè„¸å›¾åƒè´¨é‡
        
        Args:
            face_image: äººè„¸å›¾åƒ
            
        Returns:
            (æ˜¯å¦åˆæ ¼, åŸå› è¯´æ˜)
        """
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(face_image.shape) == 3:
                gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
            else:
                gray = face_image
            
            # 1. æ¨¡ç³Šæ£€æµ‹ï¼ˆæ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            if laplacian_var < 100:
                return False, f"å›¾åƒæ¨¡ç³Š (æ¸…æ™°åº¦: {laplacian_var:.1f})"
            
            # 2. å…‰ç…§æ£€æµ‹
            mean_brightness = np.mean(gray)
            if mean_brightness < 50:
                return False, f"å…‰çº¿è¿‡æš— (äº®åº¦: {mean_brightness:.1f})"
            if mean_brightness > 200:
                return False, f"å…‰çº¿è¿‡äº® (äº®åº¦: {mean_brightness:.1f})"
            
            # 3. å¯¹æ¯”åº¦æ£€æµ‹
            std_contrast = np.std(gray)
            if std_contrast < 30:
                return False, f"å¯¹æ¯”åº¦è¿‡ä½ (å¯¹æ¯”åº¦: {std_contrast:.1f})"
            
            return True, f"è´¨é‡è‰¯å¥½ (æ¸…æ™°åº¦: {laplacian_var:.1f}, äº®åº¦: {mean_brightness:.1f})"
        
        except Exception as e:
            return False, f"è´¨é‡æ£€æµ‹å¤±è´¥: {str(e)}"
    
    def augment_face(self, face_image: np.ndarray) -> List[np.ndarray]:
        """
        æ•°æ®å¢å¼ºï¼šç”Ÿæˆäººè„¸å›¾åƒçš„å¤šä¸ªå˜ä½“
        
        Args:
            face_image: åŸå§‹äººè„¸å›¾åƒ
            
        Returns:
            å¢å¼ºåçš„äººè„¸å›¾åƒåˆ—è¡¨ï¼ˆåŒ…å«åŸå›¾ï¼‰
        """
        augmented = [face_image.copy()]  # åŒ…å«åŸå›¾
        
        h, w = face_image.shape[:2]
        
        # 1. è½»å¾®æ—‹è½¬ (-5Â°, +5Â°)
        for angle in [-5, 5]:
            M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)
            rotated = cv2.warpAffine(face_image, M, (w, h), 
                                    borderMode=cv2.BORDER_REPLICATE)
            augmented.append(rotated)
        
        # 2. äº®åº¦è°ƒæ•´
        # å¢äº®10%
        hsv = cv2.cvtColor(face_image, cv2.COLOR_BGR2HSV).astype(np.float32)
        hsv[:, :, 2] = np.clip(hsv[:, :, 2] * 1.1, 0, 255)
        brightened = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
        augmented.append(brightened)
        
        # é™æš—10%
        hsv = cv2.cvtColor(face_image, cv2.COLOR_BGR2HSV).astype(np.float32)
        hsv[:, :, 2] = np.clip(hsv[:, :, 2] * 0.9, 0, 255)
        darkened = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2BGR)
        augmented.append(darkened)
        
        # 3. æ°´å¹³ç¿»è½¬ï¼ˆé•œåƒï¼‰
        flipped = cv2.flip(face_image, 1)
        augmented.append(flipped)
        
        return augmented
    
    def add_user(self, user_id: int, face_images: List[np.ndarray]):
        """
        æ·»åŠ æ–°ç”¨æˆ·
        
        Args:
            user_id: ç”¨æˆ·ID
            face_images: ç”¨æˆ·çš„äººè„¸å›¾åƒåˆ—è¡¨
        """
        print(f"\n{'='*60}")
        print(f"â• [FaceNetRecognizer] æ·»åŠ ç”¨æˆ· {user_id}")
        print(f"{'='*60}")
        
        # æ˜¾ç¤ºæ·»åŠ å‰çš„çŠ¶æ€
        if self.embeddings is not None:
            unique_labels_before = np.unique(self.labels)
            print(f"\nğŸ“Š æ·»åŠ å‰çŠ¶æ€:")
            print(f"  - æ€»æ ·æœ¬æ•°: {len(self.embeddings)}")
            print(f"  - ç”¨æˆ·æ•°: {len(unique_labels_before)}")
            print(f"  - ç”¨æˆ·IDåˆ—è¡¨: {unique_labels_before}")
            print(f"  - Labelsç±»å‹: {self.labels.dtype}")
            print(f"  - Labelsç¤ºä¾‹: {self.labels[:3] if len(self.labels) > 0 else []}")
        else:
            print(f"\nğŸ“Š æ·»åŠ å‰çŠ¶æ€: ç©ºæ¨¡å‹")
        
        # ğŸ¯ æ­¥éª¤1ï¼šè´¨é‡æ£€æµ‹
        print(f"\nğŸ” æ­¥éª¤1ï¼šè´¨é‡æ£€æµ‹ ({len(face_images)} å¼ åŸå§‹å›¾åƒ)")
        quality_passed = []
        quality_failed = []
        
        for idx, face_image in enumerate(face_images):
            is_good, reason = self.check_face_quality(face_image)
            if is_good:
                quality_passed.append(face_image)
                print(f"  âœ“ å›¾åƒ {idx+1}: {reason}")
            else:
                quality_failed.append((idx+1, reason))
                print(f"  âœ— å›¾åƒ {idx+1}: {reason}")
        
        if len(quality_failed) > 0:
            print(f"\nâš ï¸  {len(quality_failed)} å¼ å›¾åƒæœªé€šè¿‡è´¨é‡æ£€æµ‹")
        
        if len(quality_passed) == 0:
            raise ValueError("æ²¡æœ‰å›¾åƒé€šè¿‡è´¨é‡æ£€æµ‹ï¼Œè¯·é‡æ–°é‡‡é›†")
        
        print(f"âœ“ é€šè¿‡è´¨é‡æ£€æµ‹: {len(quality_passed)}/{len(face_images)} å¼ ")
        
        # ğŸ¯ æ­¥éª¤2ï¼šæ•°æ®å¢å¼º
        print(f"\nğŸ”„ æ­¥éª¤2ï¼šæ•°æ®å¢å¼º")
        print(f"  - åŸå§‹å›¾åƒ: {len(quality_passed)} å¼ ")
        print(f"  - å¢å¼ºç­–ç•¥: æ—‹è½¬ã€äº®åº¦è°ƒæ•´ã€ç¿»è½¬")
        
        all_augmented = []
        for idx, face_image in enumerate(quality_passed):
            augmented = self.augment_face(face_image)
            all_augmented.extend(augmented)
            if (idx + 1) % 5 == 0 or idx == len(quality_passed) - 1:
                print(f"  - å·²å¢å¼º {idx + 1}/{len(quality_passed)} å¼  (ç”Ÿæˆ {len(augmented)} ä¸ªå˜ä½“)")
        
        print(f"âœ“ å¢å¼ºåæ€»æ ·æœ¬æ•°: {len(all_augmented)} å¼ ")
        
        # ğŸ¯ æ­¥éª¤3ï¼šæå–ç‰¹å¾
        print(f"\nğŸ”„ æ­¥éª¤3ï¼šæå–ç‰¹å¾å‘é‡")
        new_embeddings = []
        for idx, face_image in enumerate(all_augmented):
            embedding = self.extract_embedding(face_image)
            new_embeddings.append(embedding)
            if (idx + 1) % 10 == 0 or idx == len(all_augmented) - 1:
                print(f"  - å·²æå– {idx + 1}/{len(all_augmented)} å¼ ")
        
        new_embeddings = np.array(new_embeddings)
        
        # ğŸ¯ æ­¥éª¤4ï¼šL2å½’ä¸€åŒ–ï¼ˆæé«˜åŒºåˆ†åº¦ï¼‰
        print(f"\nğŸ”„ æ­¥éª¤4ï¼šç‰¹å¾å½’ä¸€åŒ–")
        norms = np.linalg.norm(new_embeddings, axis=1, keepdims=True)
        new_embeddings = new_embeddings / norms
        print(f"âœ“ ç‰¹å¾å·²L2å½’ä¸€åŒ–")
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šç»Ÿä¸€è½¬ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…ç±»å‹æ··ä¹±
        user_id_str = str(user_id)
        new_labels = np.array([user_id_str] * len(new_embeddings), dtype=object)
        
        print(f"\nğŸ“¦ æ–°ç”¨æˆ·æ•°æ®:")
        print(f"  - ç”¨æˆ·ID: {user_id} -> '{user_id_str}' (å­—ç¬¦ä¸²)")
        print(f"  - åŸå§‹å›¾åƒ: {len(face_images)} å¼ ")
        print(f"  - è´¨é‡åˆæ ¼: {len(quality_passed)} å¼ ")
        print(f"  - å¢å¼ºå: {len(all_augmented)} å¼ ")
        print(f"  - æœ€ç»ˆæ ·æœ¬æ•°: {len(new_embeddings)} ä¸ª")
        print(f"  - Embeddingç»´åº¦: {new_embeddings.shape}")
        print(f"  - Labelsç±»å‹: {new_labels.dtype}")
        
        # åˆå¹¶åˆ°ç°æœ‰æ•°æ®
        if self.embeddings is not None:
            print(f"\nğŸ”„ åˆå¹¶åˆ°ç°æœ‰æ•°æ®...")
            # ğŸ”§ ç¡®ä¿ç°æœ‰labelsä¹Ÿæ˜¯å­—ç¬¦ä¸²ç±»å‹
            if self.labels.dtype != object:
                print(f"  âš ï¸  è½¬æ¢ç°æœ‰labelsä¸ºå­—ç¬¦ä¸²ç±»å‹")
                self.labels = self.labels.astype(str)
            
            self.embeddings = np.vstack([self.embeddings, new_embeddings])
            self.labels = np.hstack([self.labels, new_labels])
        else:
            print(f"\nğŸ“¦ åˆ›å»ºæ–°æ¨¡å‹æ•°æ®...")
            self.embeddings = new_embeddings
            self.labels = new_labels
        
        # æ˜¾ç¤ºæ·»åŠ åçš„çŠ¶æ€
        unique_labels_after = np.unique(self.labels)
        print(f"\nğŸ“Š æ·»åŠ åçŠ¶æ€:")
        print(f"  - æ€»æ ·æœ¬æ•°: {len(self.embeddings)}")
        print(f"  - ç”¨æˆ·æ•°: {len(unique_labels_after)}")
        print(f"  - ç”¨æˆ·IDåˆ—è¡¨: {unique_labels_after}")
        print(f"  - Labelsç±»å‹: {self.labels.dtype}")
        
        # é‡æ–°è®­ç»ƒSVM
        print(f"\nğŸ”„ é‡æ–°è®­ç»ƒSVM...")
        self.train_svm()
        
        # ä¿å­˜
        print(f"ğŸ’¾ ä¿å­˜æ¨¡å‹æ•°æ®...")
        self.save_trained_data()
        
        print(f"\n{'='*60}")
        print(f"âœ… ç”¨æˆ· {user_id} æ·»åŠ å®Œæˆ")
        print(f"{'='*60}\n")
    
    def train_svm(self):
        """
        è®­ç»ƒSVMåˆ†ç±»å™¨
        ä½¿ç”¨RBFæ ¸ä»¥æé«˜å¯¹ç›¸ä¼¼ç”¨æˆ·çš„åŒºåˆ†èƒ½åŠ›
        """
        from sklearn.svm import SVC
        
        # æ£€æŸ¥ç±»åˆ«æ•°é‡
        unique_labels = np.unique(self.labels)
        n_classes = len(unique_labels)
        n_samples = len(self.embeddings)
        
        if n_classes < 2:
            print(f"âš ï¸  åªæœ‰ {n_classes} ä¸ªç”¨æˆ·ï¼Œè·³è¿‡SVMè®­ç»ƒï¼ˆéœ€è¦è‡³å°‘2ä¸ªç”¨æˆ·ï¼‰")
            self.svm_model = None
            return
        
        print(f"ğŸ”„ è®­ç»ƒSVMåˆ†ç±»å™¨...")
        print(f"  - ç”¨æˆ·æ•°: {n_classes}")
        print(f"  - æ ·æœ¬æ•°: {n_samples}")
        print(f"  - æ¯ç”¨æˆ·å¹³å‡æ ·æœ¬: {n_samples/n_classes:.1f}")
        
        # ğŸ¯ ä½¿ç”¨RBFæ ¸æ›¿ä»£çº¿æ€§æ ¸ï¼Œæé«˜éçº¿æ€§åˆ†ç±»èƒ½åŠ›
        print(f"  - æ ¸å‡½æ•°: RBF (å¾„å‘åŸºå‡½æ•°)")
        print(f"  - æ­£åˆ™åŒ–å‚æ•° C: 10.0")
        print(f"  - æ ¸ç³»æ•° gamma: scale")
        
        self.svm_model = SVC(
            kernel='rbf',              # RBFæ ¸ï¼Œé€‚åˆéçº¿æ€§åˆ†ç±»
            C=10.0,                    # æ­£åˆ™åŒ–å‚æ•°ï¼Œæ§åˆ¶åˆ†ç±»è¾¹ç•Œçš„è½¯ç¡¬ç¨‹åº¦
            gamma='scale',             # æ ¸ç³»æ•°ï¼Œè‡ªåŠ¨æ ¹æ®ç‰¹å¾æ•°é‡è°ƒæ•´
            probability=True,          # å¯ç”¨æ¦‚ç‡ä¼°è®¡
            class_weight='balanced'    # è‡ªåŠ¨å¹³è¡¡ç±»åˆ«æƒé‡
        )
        
        self.svm_model.fit(self.embeddings, self.labels)
        print(f"âœ“ SVMè®­ç»ƒå®Œæˆ")
        print(f"  - æ”¯æŒå‘é‡æ•°: {len(self.svm_model.support_)}")
        print(f"  - æ”¯æŒå‘é‡å æ¯”: {len(self.svm_model.support_)/n_samples*100:.1f}%")
    
    def save_trained_data(self):
        """ä¿å­˜è®­ç»ƒæ•°æ®"""
        # ä¿å­˜ç‰¹å¾
        np.savez(
            self.embeddings_path,
            embeddings=self.embeddings,
            labels=self.labels
        )
        
        # ä¿å­˜SVM
        with open(self.svm_path, 'wb') as f:
            pickle.dump(self.svm_model, f)
        
        print(f"âœ“ è®­ç»ƒæ•°æ®å·²ä¿å­˜")
    
    def remove_user(self, user_id: int):
        """
        åˆ é™¤ç”¨æˆ·
        
        Args:
            user_id: ç”¨æˆ·ID
        """
        print(f"\n{'='*60}")
        print(f"ğŸ—‘ï¸  [FaceNetRecognizer] å¼€å§‹åˆ é™¤ç”¨æˆ· {user_id}")
        print(f"{'='*60}")
        
        if self.embeddings is None or self.labels is None:
            print("âš ï¸  æ²¡æœ‰è®­ç»ƒæ•°æ®ï¼Œè·³è¿‡åˆ é™¤")
            return
        
        # æ˜¾ç¤ºåˆ é™¤å‰çš„çŠ¶æ€
        unique_labels_before = np.unique(self.labels)
        print(f"\nğŸ“Š åˆ é™¤å‰çŠ¶æ€:")
        print(f"  - æ€»æ ·æœ¬æ•°: {len(self.embeddings)}")
        print(f"  - ç”¨æˆ·æ•°: {len(unique_labels_before)}")
        print(f"  - ç”¨æˆ·IDåˆ—è¡¨: {unique_labels_before}")
        
        # ç»Ÿè®¡è¦åˆ é™¤çš„ç”¨æˆ·çš„æ ·æœ¬æ•°
        # æ³¨æ„ï¼šlabelså¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•´æ•°ï¼Œéœ€è¦ç»Ÿä¸€æ¯”è¾ƒ
        user_id_str = str(user_id)
        user_samples_int = np.sum(self.labels == user_id)
        user_samples_str = np.sum(self.labels == user_id_str)
        user_samples = user_samples_int + user_samples_str
        
        print(f"\nğŸ¯ ç›®æ ‡ç”¨æˆ· {user_id}:")
        print(f"  - æ ·æœ¬æ•°ï¼ˆæ•´æ•°åŒ¹é…ï¼‰: {user_samples_int}")
        print(f"  - æ ·æœ¬æ•°ï¼ˆå­—ç¬¦ä¸²åŒ¹é…ï¼‰: {user_samples_str}")
        print(f"  - æ€»æ ·æœ¬æ•°: {user_samples}")
        
        if user_samples == 0:
            print(f"âš ï¸  ç”¨æˆ· {user_id} æ²¡æœ‰æ ·æœ¬ï¼Œæ— éœ€åˆ é™¤")
            return
        
        # è¿‡æ»¤æ‰è¯¥ç”¨æˆ·çš„æ•°æ®ï¼ˆåŒæ—¶åŒ¹é…æ•´æ•°å’Œå­—ç¬¦ä¸²ï¼‰
        print(f"\nğŸ”„ å¼€å§‹è¿‡æ»¤æ•°æ®...")
        mask = (self.labels != user_id) & (self.labels != user_id_str)
        self.embeddings = self.embeddings[mask]
        self.labels = self.labels[mask]
        
        # æ˜¾ç¤ºåˆ é™¤åçš„çŠ¶æ€
        unique_labels_after = np.unique(self.labels) if len(self.labels) > 0 else np.array([])
        print(f"\nğŸ“Š åˆ é™¤åçŠ¶æ€:")
        print(f"  - æ€»æ ·æœ¬æ•°: {len(self.embeddings)}")
        print(f"  - ç”¨æˆ·æ•°: {len(unique_labels_after)}")
        print(f"  - ç”¨æˆ·IDåˆ—è¡¨: {unique_labels_after}")
        print(f"  - å·²åˆ é™¤æ ·æœ¬æ•°: {user_samples}")
        
        # é‡æ–°è®­ç»ƒ
        if len(self.embeddings) > 0:
            print(f"\nğŸ”„ é‡æ–°è®­ç»ƒæ¨¡å‹...")
            self.train_svm()
            print(f"ğŸ’¾ ä¿å­˜æ›´æ–°åçš„æ¨¡å‹æ–‡ä»¶...")
            self.save_trained_data()
            print(f"âœ… æ¨¡å‹å·²æ›´æ–°å¹¶ä¿å­˜")
        else:
            print("âš ï¸  æ‰€æœ‰ç”¨æˆ·å·²åˆ é™¤ï¼Œæ¸…ç©ºæ¨¡å‹")
            self.svm_model = None
        
        print(f"\n{'='*60}")
        print(f"âœ… ç”¨æˆ· {user_id} åˆ é™¤å®Œæˆ")
        print(f"{'='*60}\n")
    
    def get_user_count(self) -> int:
        """è·å–æ³¨å†Œç”¨æˆ·æ•°é‡"""
        if self.labels is None:
            return 0
        return len(np.unique(self.labels))
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if self.facenet_model is not None:
            del self.facenet_model
        if torch.cuda.is_available():
            torch.cuda.empty_cache()


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    recognizer = FaceNetRecognizer()
    
    print(f"æ³¨å†Œç”¨æˆ·æ•°: {recognizer.get_user_count()}")
    
    # æµ‹è¯•è¯†åˆ«
    cap = cv2.VideoCapture(0)
    from yolo_face_detector import YOLOFaceDetector
    detector = YOLOFaceDetector()
    
    print("æŒ‰ 'q' é€€å‡º")
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æ£€æµ‹äººè„¸
        faces = detector.detect_faces(frame, return_confidence=True)
        
        for face in faces:
            x1, y1, x2, y2 = face[:4]
            
            # è£å‰ªäººè„¸
            face_img = detector.crop_face(frame, face)
            if face_img is not None:
                # è¯†åˆ«
                user_id, confidence = recognizer.recognize(face_img)
                
                # ç»˜åˆ¶
                color = (0, 255, 0) if user_id is not None else (0, 0, 255)
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                
                text = f"User {user_id} ({confidence:.2f})" if user_id else "Unknown"
                cv2.putText(frame, text, (x1, y1 - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        cv2.imshow('Face Recognition', frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
