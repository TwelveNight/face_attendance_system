"""
FaceNet‰∫∫ËÑ∏ËØÜÂà´ÊµãËØïËÑöÊú¨
ÂÆûÊó∂ÊµãËØïËÆ≠ÁªÉÂ•ΩÁöÑFaceNet+SVMÊ®°Âûã
"""
import numpy as np
import pickle
import torch
import cv2
import logging
import sys
from pathlib import Path

# Ê∑ªÂä†backendÁõÆÂΩïÂà∞Ë∑ØÂæÑ
backend_dir = Path(__file__).parent.parent.parent
sys.path.insert(0, str(backend_dir))

from facenet_pytorch import InceptionResnetV1
from config import config
from train.common import YOLOFaceDetector

# ÈÖçÁΩÆÊó•Âøó
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class FaceRecognitionTester:
    """‰∫∫ËÑ∏ËØÜÂà´ÊµãËØïÂô®"""
    
    def __init__(
        self,
        embeddings_path: str = None,
        svm_path: str = None,
        yolo_path: str = None,
        device: str = None
    ):
        """ÂàùÂßãÂåñÊµãËØïÂô®"""
        # ËÆæÁΩÆË∑ØÂæÑ
        if embeddings_path is None:
            embeddings_path = str(config.FACENET_EMBEDDINGS)
        if svm_path is None:
            svm_path = str(config.FACENET_SVM)
        if yolo_path is None:
            yolo_path = str(config.YOLO_MODEL)
        
        # ËÆæÁΩÆËÆæÂ§á
        if device is None:
            self.device = config.get_device()
        else:
            self.device = torch.device(device)
        
        logger.info(f"‰ΩøÁî®ËÆæÂ§á: {self.device}")
        
        # Âä†ËΩΩYOLO
        self.detector = YOLOFaceDetector(
            model_path=yolo_path,
            confidence_threshold=config.YOLO_CONFIDENCE_THRESHOLD
        )
        
        # Âä†ËΩΩFaceNet
        logger.info("Âä†ËΩΩFaceNetÊ®°Âûã...")
        self.facenet = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)
        logger.info("‚úì FaceNetÂ∑≤Âä†ËΩΩ")
        
        # Âä†ËΩΩSVMÊ®°Âûã
        logger.info(f"Âä†ËΩΩSVMÊ®°Âûã: {svm_path}")
        with open(svm_path, 'rb') as f:
            model_data = pickle.load(f)
        
        # üîß ‰øÆÂ§çÔºöÂÖºÂÆπÊñ∞ÊóßÊ†ºÂºè
        # Êñ∞Ê†ºÂºèÔºöÁõ¥Êé•‰øùÂ≠òSVCÂØπË±°
        # ÊóßÊ†ºÂºèÔºö‰øùÂ≠òÂ≠óÂÖ∏ {'svm': SVC, 'label_encoder': LabelEncoder}
        if isinstance(model_data, dict):
            # ÊóßÊ†ºÂºè
            self.svm = model_data['svm']
            self.label_encoder = model_data['label_encoder']
            logger.info(f"‚úì SVMÂ∑≤Âä†ËΩΩ (ÊóßÊ†ºÂºè),ÊîØÊåÅ {len(self.label_encoder.classes_)} ‰∏™Áî®Êà∑")
        else:
            # Êñ∞Ê†ºÂºèÔºöÁõ¥Êé•ÊòØSVCÂØπË±°
            self.svm = model_data
            self.label_encoder = None  # Êñ∞Ê†ºÂºè‰∏çÈúÄË¶Ålabel_encoder
            logger.info(f"‚úì SVMÂ∑≤Âä†ËΩΩ (Êñ∞Ê†ºÂºè),ÊîØÊåÅ {len(self.svm.classes_)} ‰∏™Áî®Êà∑")
        
        # ÊòæÁ§∫Áî®Êà∑ÂàóË°®
        if self.label_encoder:
            logger.info(f"  Áî®Êà∑ÂàóË°®: {list(self.label_encoder.classes_)}")
        else:
            logger.info(f"  Áî®Êà∑ÂàóË°®: {list(self.svm.classes_)}")
    
    def extract_embedding(self, face_image: np.ndarray) -> np.ndarray:
        """ÊèêÂèñ‰∫∫ËÑ∏ÂµåÂÖ•ÂêëÈáè"""
        # BGR to RGB
        face_rgb = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)
        face_resized = cv2.resize(face_rgb, config.FACE_SIZE)
        
        # ËΩ¨Êç¢‰∏∫tensor
        face_tensor = torch.from_numpy(face_resized).float()
        face_tensor = face_tensor.permute(2, 0, 1)
        face_tensor = (face_tensor - 127.5) / 128.0
        face_tensor = face_tensor.unsqueeze(0).to(self.device)
        
        # ÊèêÂèñÁâπÂæÅ
        with torch.no_grad():
            embedding = self.facenet(face_tensor)
        
        return embedding.cpu().numpy().flatten()
    
    def recognize_face(self, face_image: np.ndarray) -> tuple:
        """
        ËØÜÂà´‰∫∫ËÑ∏
        
        Returns:
            (Áî®Êà∑Âêç/ID, ÁΩÆ‰ø°Â∫¶)
        """
        # ÊèêÂèñÂµåÂÖ•
        embedding = self.extract_embedding(face_image)
        
        # SVMÈ¢ÑÊµã
        prediction = self.svm.predict([embedding])[0]
        probabilities = self.svm.predict_proba([embedding])[0]
        
        # üîß ‰øÆÂ§çÔºöÂÖºÂÆπÊñ∞ÊóßÊ†ºÂºè
        if self.label_encoder:
            # ÊóßÊ†ºÂºèÔºö‰ΩøÁî®label_encoderËß£Á†Å
            user_name = self.label_encoder.inverse_transform([prediction])[0]
            confidence = probabilities[prediction]
        else:
            # Êñ∞Ê†ºÂºèÔºöpredictionÁõ¥Êé•ÊòØÁî®Êà∑IDÔºàÂ≠óÁ¨¶‰∏≤Ôºâ
            user_name = prediction
            # Ëé∑ÂèñÂØπÂ∫îÁ±ªÂà´ÁöÑÊ¶ÇÁéá
            class_idx = list(self.svm.classes_).index(prediction)
            confidence = probabilities[class_idx]
        
        return user_name, confidence
    
    def test_realtime(self, camera_index: int = 0, confidence_threshold: float = 0.5):
        """ÂÆûÊó∂ÊµãËØï"""
        logger.info("\n" + "=" * 60)
        logger.info("FaceNet ‰∫∫ËÑ∏ËØÜÂà´ÂÆûÊó∂ÊµãËØï")
        logger.info("=" * 60)
        logger.info("Êåâ 'q' ÈÄÄÂá∫\n")
        
        cap = cv2.VideoCapture(camera_index)
        if not cap.isOpened():
            logger.error(f"Êó†Ê≥ïÊâìÂºÄÊëÑÂÉèÂ§¥ {camera_index}")
            return
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # Ê£ÄÊµã‰∫∫ËÑ∏
            face = self.detector.detect_single_face(frame, margin=20)
            
            # ÊòæÁ§∫ÁîªÈù¢
            display_frame = frame.copy()
            
            if face is not None:
                # ËØÜÂà´
                try:
                    user_name, confidence = self.recognize_face(face)
                    
                    # ÁªòÂà∂ÁªìÊûú
                    boxes = self.detector.detect_faces(frame)
                    if boxes:
                        x1, y1, x2, y2 = boxes[0]
                        
                        # Ê†πÊçÆÁΩÆ‰ø°Â∫¶ÈÄâÊã©È¢úËâ≤
                        if confidence >= confidence_threshold:
                            color = (0, 255, 0)  # ÁªøËâ≤ - ËØÜÂà´ÊàêÂäü
                            text = f"{user_name} ({confidence:.2f})"
                        else:
                            color = (0, 165, 255)  # Ê©ôËâ≤ - ÁΩÆ‰ø°Â∫¶‰Ωé
                            text = f"Unknown ({confidence:.2f})"
                        
                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)
                        cv2.putText(
                            display_frame,
                            text,
                            (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.7,
                            color,
                            2
                        )
                    
                except Exception as e:
                    logger.error(f"ËØÜÂà´Â§±Ë¥•: {e}")
            else:
                # Êú™Ê£ÄÊµãÂà∞‰∫∫ËÑ∏
                cv2.putText(
                    display_frame,
                    "No face detected",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    (0, 0, 255),
                    2
                )
            
            cv2.imshow('Face Recognition Test', display_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()


def main():
    """ÊµãËØïÂÖ•Âè£"""
    tester = FaceRecognitionTester()
    tester.test_realtime(confidence_threshold=0.6)


if __name__ == '__main__':
    main()
