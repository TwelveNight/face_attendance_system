"""
äººè„¸æœåŠ¡
å¤„ç†äººè„¸æ£€æµ‹å’Œè¯†åˆ«çš„ä¸šåŠ¡é€»è¾‘
"""
import numpy as np
import cv2
from typing import Optional, Tuple, List, Dict
from pathlib import Path

from models.model_manager import model_manager
from config.settings import Config


class FaceService:
    """äººè„¸æ£€æµ‹å’Œè¯†åˆ«æœåŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–äººè„¸æœåŠ¡"""
        # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
        if not model_manager.is_loaded():
            model_manager.load_models()
        
        self.detector = model_manager.yolo_detector
        self.recognizer = model_manager.facenet_recognizer
    
    def detect_and_recognize(self, image: np.ndarray) -> List[Dict]:
        """
        æ£€æµ‹å¹¶è¯†åˆ«å›¾åƒä¸­çš„æ‰€æœ‰äººè„¸
        
        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼)
            
        Returns:
            List of {
                'bbox': (x1, y1, x2, y2),
                'user_id': int or None,
                'confidence': float,
                'detection_confidence': float
            }
        """
        results = []
        
        # æ£€æµ‹äººè„¸
        faces = self.detector.detect_faces(image, return_confidence=True)
        
        for face in faces:
            x1, y1, x2, y2, det_conf = face
            
            # è£å‰ªäººè„¸
            face_img = self.detector.crop_face(image, face)
            
            if face_img is not None and face_img.size > 0:
                # è¯†åˆ«
                user_id, rec_conf = self.recognizer.recognize(face_img)
                
                results.append({
                    'bbox': (x1, y1, x2, y2),
                    'user_id': user_id,
                    'confidence': rec_conf,
                    'detection_confidence': det_conf
                })
        
        return results
    
    def detect_largest_face_and_recognize(self, image: np.ndarray) -> Optional[Dict]:
        """
        æ£€æµ‹æœ€å¤§çš„äººè„¸å¹¶è¯†åˆ«
        
        Args:
            image: è¾“å…¥å›¾åƒ
            
        Returns:
            {
                'bbox': (x1, y1, x2, y2),
                'user_id': int or None,
                'confidence': float,
                'detection_confidence': float
            } or None
        """
        # æ£€æµ‹æœ€å¤§äººè„¸
        face = self.detector.detect_largest_face(image)
        
        if face is None:
            return None
        
        x1, y1, x2, y2, det_conf = face
        
        # è£å‰ªå¹¶è¯†åˆ«
        face_img = self.detector.crop_face(image, face)
        
        if face_img is None or face_img.size == 0:
            return None
        
        user_id, rec_conf = self.recognizer.recognize(face_img)
        
        return {
            'bbox': (x1, y1, x2, y2),
            'user_id': user_id,
            'confidence': rec_conf,
            'detection_confidence': det_conf
        }
    
    def register_user_faces(self, user_id: int, images: List[np.ndarray]) -> bool:
        """
        æ³¨å†Œç”¨æˆ·äººè„¸
        
        Args:
            user_id: ç”¨æˆ·ID
            images: äººè„¸å›¾åƒåˆ—è¡¨
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            print(f"ğŸ” å¼€å§‹å¤„ç†ç”¨æˆ· {user_id} çš„äººè„¸å›¾åƒ...")
            print(f"   æ”¶åˆ°å›¾åƒæ•°é‡: {len(images)}")
            
            # ä»æ¯å¼ å›¾åƒä¸­æå–äººè„¸
            face_images = []
            
            for idx, image in enumerate(images):
                print(f"   å¤„ç†ç¬¬ {idx+1}/{len(images)} å¼ å›¾åƒ...")
                
                # æ£€æµ‹æœ€å¤§äººè„¸
                face = self.detector.detect_largest_face(image)
                
                if face is not None:
                    print(f"   âœ“ æ£€æµ‹åˆ°äººè„¸")
                    # è£å‰ªäººè„¸
                    face_img = self.detector.crop_face(image, face)
                    if face_img is not None and face_img.size > 0:
                        face_images.append(face_img)
                        print(f"   âœ“ äººè„¸è£å‰ªæˆåŠŸ")
                    else:
                        print(f"   âœ— äººè„¸è£å‰ªå¤±è´¥")
                else:
                    print(f"   âœ— æœªæ£€æµ‹åˆ°äººè„¸")
            
            if len(face_images) == 0:
                print(f"âŒ æœªæ£€æµ‹åˆ°ä»»ä½•æœ‰æ•ˆäººè„¸")
                return False
            
            print(f"âœ“ æˆåŠŸæå– {len(face_images)} å¼ äººè„¸å›¾åƒ")
            
            # æ·»åŠ åˆ°è¯†åˆ«å™¨
            print(f"ğŸ”„ æ·»åŠ ç”¨æˆ·åˆ°è¯†åˆ«å™¨å¹¶è®­ç»ƒæ¨¡å‹...")
            self.recognizer.add_user(user_id, face_images)
            
            print(f"âœ… ç”¨æˆ· {user_id} äººè„¸æ³¨å†ŒæˆåŠŸ ({len(face_images)} å¼ äººè„¸)")
            return True
        
        except Exception as e:
            print(f"âŒ ç”¨æˆ·æ³¨å†Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def update_user_faces(self, user_id: int, images: List[np.ndarray]) -> bool:
        """
        æ›´æ–°ç”¨æˆ·äººè„¸
        
        Args:
            user_id: ç”¨æˆ·ID
            images: æ–°çš„äººè„¸å›¾åƒåˆ—è¡¨
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # å…ˆåˆ é™¤æ—§æ•°æ®
            self.recognizer.remove_user(user_id)
            
            # é‡æ–°æ³¨å†Œ
            return self.register_user_faces(user_id, images)
        
        except Exception as e:
            print(f"âœ— æ›´æ–°ç”¨æˆ·äººè„¸å¤±è´¥: {e}")
            return False
    
    def remove_user_faces(self, user_id: int) -> bool:
        """
        åˆ é™¤ç”¨æˆ·äººè„¸æ•°æ®
        
        Args:
            user_id: ç”¨æˆ·ID
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            self.recognizer.remove_user(user_id)
            print(f"âœ“ ç”¨æˆ· {user_id} äººè„¸æ•°æ®å·²åˆ é™¤")
            return True
        
        except Exception as e:
            print(f"âœ— åˆ é™¤ç”¨æˆ·äººè„¸æ•°æ®å¤±è´¥: {e}")
            return False
    
    def collect_faces_from_video(self, video_source: int = 0, 
                                 count: int = None) -> List[np.ndarray]:
        """
        ä»è§†é¢‘æµé‡‡é›†äººè„¸
        
        Args:
            video_source: è§†é¢‘æº(æ‘„åƒå¤´ç´¢å¼•æˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„)
            count: é‡‡é›†æ•°é‡
            
        Returns:
            é‡‡é›†åˆ°çš„äººè„¸å›¾åƒåˆ—è¡¨
        """
        if count is None:
            count = Config.REGISTER_FACE_COUNT
        
        cap = cv2.VideoCapture(video_source)
        collected_faces = []
        
        print(f"å¼€å§‹é‡‡é›†äººè„¸ (ç›®æ ‡: {count} å¼ )")
        print("æŒ‰ 'c' é‡‡é›†, 'q' é€€å‡º")
        
        while len(collected_faces) < count:
            ret, frame = cap.read()
            if not ret:
                break
            
            # æ£€æµ‹äººè„¸
            face = self.detector.detect_largest_face(frame)
            
            display = frame.copy()
            
            if face is not None:
                x1, y1, x2, y2, conf = face
                cv2.rectangle(display, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(display, f"Conf: {conf:.2f}", (x1, y1 - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = f"Collected: {len(collected_faces)}/{count}"
            cv2.putText(display, progress, (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            cv2.imshow('Face Collection', display)
            
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('c') and face is not None:
                # é‡‡é›†äººè„¸
                face_img = self.detector.crop_face(frame, face)
                if face_img is not None:
                    collected_faces.append(face_img)
                    print(f"  é‡‡é›† {len(collected_faces)}/{count}")
            
            elif key == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        
        print(f"âœ“ é‡‡é›†å®Œæˆ: {len(collected_faces)} å¼ äººè„¸")
        return collected_faces
    
    def draw_results(self, image: np.ndarray, results: List[Dict]) -> np.ndarray:
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹å’Œè¯†åˆ«ç»“æœ
        
        Args:
            image: è¾“å…¥å›¾åƒ
            results: æ£€æµ‹è¯†åˆ«ç»“æœ
            
        Returns:
            ç»˜åˆ¶åçš„å›¾åƒ
        """
        output = image.copy()
        
        for result in results:
            x1, y1, x2, y2 = result['bbox']
            user_id = result['user_id']
            confidence = result['confidence']
            
            # é¢œè‰²: ç»¿è‰²(å·²è¯†åˆ«) çº¢è‰²(æœªè¯†åˆ«)
            color = (0, 255, 0) if user_id is not None else (0, 0, 255)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(output, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ–‡æœ¬
            if user_id is not None:
                text = f"User {user_id} ({confidence:.2f})"
            else:
                text = "Unknown"
            
            cv2.putText(output, text, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        return output
    
    def get_registered_user_count(self) -> int:
        """è·å–å·²æ³¨å†Œç”¨æˆ·æ•°é‡"""
        return self.recognizer.get_user_count()


if __name__ == '__main__':
    # æµ‹è¯•äººè„¸æœåŠ¡
    service = FaceService()
    
    print(f"å·²æ³¨å†Œç”¨æˆ·æ•°: {service.get_registered_user_count()}")
    
    # æµ‹è¯•å®æ—¶è¯†åˆ«
    cap = cv2.VideoCapture(0)
    
    print("æŒ‰ 'q' é€€å‡º")
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æ£€æµ‹å¹¶è¯†åˆ«
        results = service.detect_and_recognize(frame)
        
        # ç»˜åˆ¶ç»“æœ
        output = service.draw_results(frame, results)
        
        cv2.imshow('Face Service Test', output)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
